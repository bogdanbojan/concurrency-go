# Concurrency at Scale #

## Error Propagation ##

Go attempts to correct the ferrying up the stack of errors without much tought and ultimately dumping them in front of the user. It does this by forcing users to handle errors at every frame in the call stack..thus hindering the use of errors as second-class citizens to the system's control flow.

When errors occur, is useful to have these in mind:
- what happened
- when and where it occurred
- a friendly user-facing message
- how the user can get more information 

By default, no error will contain all of this information without your intervention. This leads to a framework that enables us to place all errors into one of two categories:
- bugs
- known edge cases(e.g. broken network connections, failed disk writes, etc)

Bugs being "raw" errors - which sometimes can be intentional especially in the first few iterations of the system.

A well-formed error could look like:

```
type MyError struct {
	Inner      error
	Message    string
	StackTrace string
	Misc       map[string]interface{}
}

func wrapError(err error, messagef string, msgArgs ...interface{}) MyError {
	return MyError{
		Inner:      err, 
		Message:    fmt.Sprintf(messagef, msgArgs...),
		StackTrace: string(debug.Stack()),        
		Misc:       make(map[string]interface{}),
	}
}

func (err MyError) Error() string {
	return err.Message
}
```

## Timeouts and Cancellation ##

Timeouts and cancelations are crucial in order to create a system with a behaviour you can understand. Cancellation being a natural response to a time out.

Why do we want time outs?
- System saturation (i.e. its ability to process requests is at capacity). When do we time out?: 
    - if we can't store the request
    - if the need for the request or the data is going stale
    - if the request is unlikely to be repeated when it is timed out

- Stale data
    - sometimes data has a window within which it must pe processed before relevant data is available or the need to process data has expired. We can use the `Context` package to manage that.

- Attempting to prevent deadlocks
    - It is not unreasonable, even recommended, to place timeouts on *all* of your concurrent operations to guarantee the system won't deadlock. There is a possibility that you introduce livelocks this way..